{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob(path + 'data/train/*.png'))\n",
    "test_png = sorted(glob(path + 'data/test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atSgPJRn-OCW",
    "outputId": "87b6f90b-5c1c-4a0e-de54-994458543687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4277, 2154)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"data/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4277/4277 [02:04<00:00, 34.43it/s]\n",
      "100%|███████████████████████████████████████| 2154/2154 [01:02<00:00, 34.61it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "np.save(path + 'data/train_imgs_384', np.array(train_imgs))\n",
    "np.save(path + 'data/test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'data/train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'data/test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sscGLiJKPy6H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sscGLiJKPy6H",
    "outputId": "976516c0-507d-458f-f0c4-6695751605d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.4330380901867049 0.4034575319032911 0.39415050509784405\n",
      "train 표준편차 0.1815717110252788 0.17403455556798705 0.16323395055036488\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"train 평균\",meanR, meanG, meanB)\n",
    "print(\"train 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "JwVIQCrUSCFE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwVIQCrUSCFE",
    "outputId": "293981ef-7f6a-4602-d208-5fd8473d5261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.41825619520929724 0.3931011906330291 0.386631764639131\n",
      "test 표준편차 0.19505524270747931 0.19005280951759498 0.18053225852732663\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"test 평균\",meanR, meanG, meanB)\n",
    "print(\"test 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                     std = [0.181572, 0.174035, 0.163234]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=88, drop_path_rate = 0.2)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=88, drop_path_rate = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "EnOG2n30-Dz5",
   "metadata": {
    "id": "EnOG2n30-Dz5"
   },
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b3_ra2-cf984f9c.pth\" to /home/lab20/.cache/torch/hub/checkpoints/efficientnet_b3_ra2-cf984f9c.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 96s/6595s\n",
      "TRAIN    loss : 1.18217    f1 : 0.18602\n",
      "Val    loss : 0.62408    f1 : 0.25515\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 88s/5969s\n",
      "TRAIN    loss : 0.55791    f1 : 0.36260\n",
      "Val    loss : 0.46246    f1 : 0.40098\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 89s/5965s\n",
      "TRAIN    loss : 0.39060    f1 : 0.51017\n",
      "Val    loss : 0.33407    f1 : 0.54776\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 89s/5895s\n",
      "TRAIN    loss : 0.28324    f1 : 0.63564\n",
      "Val    loss : 0.35030    f1 : 0.60441\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 90s/5851s\n",
      "TRAIN    loss : 0.24072    f1 : 0.68668\n",
      "Val    loss : 0.22283    f1 : 0.65025\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 90s/5765s\n",
      "TRAIN    loss : 0.16152    f1 : 0.80172\n",
      "Val    loss : 0.19800    f1 : 0.70202\n",
      "epoch : 7/70    time : 90s/5679s\n",
      "TRAIN    loss : 0.12204    f1 : 0.84268\n",
      "Val    loss : 0.19118    f1 : 0.69870\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/70    time : 91s/5629s\n",
      "TRAIN    loss : 0.09648    f1 : 0.87902\n",
      "Val    loss : 0.19356    f1 : 0.70862\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/70    time : 90s/5518s\n",
      "TRAIN    loss : 0.08530    f1 : 0.89991\n",
      "Val    loss : 0.13785    f1 : 0.76162\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/70    time : 90s/5422s\n",
      "TRAIN    loss : 0.07578    f1 : 0.90907\n",
      "Val    loss : 0.17839    f1 : 0.76715\n",
      "epoch : 11/70    time : 90s/5322s\n",
      "TRAIN    loss : 0.06197    f1 : 0.93235\n",
      "Val    loss : 0.16775    f1 : 0.75475\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/70    time : 91s/5256s\n",
      "TRAIN    loss : 0.05734    f1 : 0.93761\n",
      "Val    loss : 0.17148    f1 : 0.77536\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/70    time : 90s/5157s\n",
      "TRAIN    loss : 0.04515    f1 : 0.95277\n",
      "Val    loss : 0.21335    f1 : 0.77724\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/70    time : 90s/5057s\n",
      "TRAIN    loss : 0.03726    f1 : 0.95804\n",
      "Val    loss : 0.19978    f1 : 0.78503\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/70    time : 90s/4959s\n",
      "TRAIN    loss : 0.03844    f1 : 0.95937\n",
      "Val    loss : 0.19207    f1 : 0.78983\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/70    time : 91s/4897s\n",
      "TRAIN    loss : 0.03969    f1 : 0.96311\n",
      "Val    loss : 0.18067    f1 : 0.78984\n",
      "epoch : 17/70    time : 90s/4783s\n",
      "TRAIN    loss : 0.02528    f1 : 0.96720\n",
      "Val    loss : 0.15319    f1 : 0.78161\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/70    time : 91s/4716s\n",
      "TRAIN    loss : 0.01872    f1 : 0.98400\n",
      "Val    loss : 0.18488    f1 : 0.80006\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/70    time : 90s/4615s\n",
      "TRAIN    loss : 0.03022    f1 : 0.96951\n",
      "Val    loss : 0.12051    f1 : 0.82612\n",
      "epoch : 20/70    time : 90s/4506s\n",
      "TRAIN    loss : 0.04024    f1 : 0.95748\n",
      "Val    loss : 0.21051    f1 : 0.75179\n",
      "epoch : 21/70    time : 90s/4396s\n",
      "TRAIN    loss : 0.03294    f1 : 0.96851\n",
      "Val    loss : 0.18356    f1 : 0.76623\n",
      "epoch : 22/70    time : 90s/4317s\n",
      "TRAIN    loss : 0.02099    f1 : 0.97323\n",
      "Val    loss : 0.17195    f1 : 0.80570\n",
      "epoch : 23/70    time : 90s/4238s\n",
      "TRAIN    loss : 0.02291    f1 : 0.97064\n",
      "Val    loss : 0.18224    f1 : 0.80435\n",
      "epoch : 24/70    time : 90s/4131s\n",
      "TRAIN    loss : 0.01558    f1 : 0.98733\n",
      "Val    loss : 0.25139    f1 : 0.74935\n",
      "epoch : 25/70    time : 90s/4063s\n",
      "TRAIN    loss : 0.03026    f1 : 0.96847\n",
      "Val    loss : 0.17121    f1 : 0.79204\n",
      "-----------------SAVE:26 epoch----------------\n",
      "epoch : 26/70    time : 91s/3992s\n",
      "TRAIN    loss : 0.02739    f1 : 0.97283\n",
      "Val    loss : 0.19168    f1 : 0.84155\n",
      "epoch : 27/70    time : 90s/3880s\n",
      "TRAIN    loss : 0.01643    f1 : 0.98630\n",
      "Val    loss : 0.16295    f1 : 0.79259\n",
      "epoch : 28/70    time : 90s/3786s\n",
      "TRAIN    loss : 0.01965    f1 : 0.98712\n",
      "Val    loss : 0.16919    f1 : 0.79444\n",
      "epoch : 29/70    time : 90s/3701s\n",
      "TRAIN    loss : 0.03147    f1 : 0.97124\n",
      "Val    loss : 0.17900    f1 : 0.76898\n",
      "epoch : 30/70    time : 90s/3613s\n",
      "TRAIN    loss : 0.02024    f1 : 0.97602\n",
      "Val    loss : 0.21559    f1 : 0.79059\n",
      "epoch : 31/70    time : 90s/3521s\n",
      "TRAIN    loss : 0.02138    f1 : 0.97956\n",
      "Val    loss : 0.24856    f1 : 0.77930\n",
      "epoch : 32/70    time : 90s/3410s\n",
      "TRAIN    loss : 0.02594    f1 : 0.97925\n",
      "Val    loss : 0.15959    f1 : 0.81049\n",
      "epoch : 33/70    time : 90s/3341s\n",
      "TRAIN    loss : 0.01433    f1 : 0.98277\n",
      "Val    loss : 0.17276    f1 : 0.83383\n",
      "epoch : 34/70    time : 90s/3231s\n",
      "TRAIN    loss : 0.01385    f1 : 0.98871\n",
      "Val    loss : 0.14968    f1 : 0.81609\n",
      "epoch : 35/70    time : 90s/3160s\n",
      "TRAIN    loss : 0.02799    f1 : 0.97958\n",
      "Val    loss : 0.16440    f1 : 0.79747\n",
      "epoch : 36/70    time : 90s/3061s\n",
      "TRAIN    loss : 0.02669    f1 : 0.96828\n",
      "Val    loss : 0.15080    f1 : 0.81298\n",
      "epoch : 37/70    time : 90s/2960s\n",
      "TRAIN    loss : 0.01874    f1 : 0.99118\n",
      "Val    loss : 0.13435    f1 : 0.81792\n",
      "epoch : 38/70    time : 90s/2883s\n",
      "TRAIN    loss : 0.01015    f1 : 0.98880\n",
      "Val    loss : 0.14884    f1 : 0.81541\n",
      "epoch : 39/70    time : 90s/2777s\n",
      "TRAIN    loss : 0.01083    f1 : 0.98871\n",
      "Val    loss : 0.14951    f1 : 0.83975\n",
      "epoch : 40/70    time : 90s/2701s\n",
      "TRAIN    loss : 0.01552    f1 : 0.98555\n",
      "Val    loss : 0.12532    f1 : 0.80236\n",
      "epoch : 41/70    time : 90s/2600s\n",
      "TRAIN    loss : 0.00946    f1 : 0.99288\n",
      "Val    loss : 0.14105    f1 : 0.83078\n",
      "epoch : 42/70    time : 90s/2510s\n",
      "TRAIN    loss : 0.00537    f1 : 0.99348\n",
      "Val    loss : 0.15807    f1 : 0.83074\n",
      "epoch : 43/70    time : 90s/2430s\n",
      "TRAIN    loss : 0.00757    f1 : 0.99199\n",
      "Val    loss : 0.16798    f1 : 0.80036\n",
      "epoch : 44/70    time : 90s/2329s\n",
      "TRAIN    loss : 0.00625    f1 : 0.99216\n",
      "Val    loss : 0.17694    f1 : 0.83199\n",
      "epoch : 45/70    time : 90s/2245s\n",
      "TRAIN    loss : 0.00505    f1 : 0.99240\n",
      "Val    loss : 0.17132    f1 : 0.79687\n",
      "epoch : 46/70    time : 90s/2166s\n",
      "TRAIN    loss : 0.02963    f1 : 0.97672\n",
      "Val    loss : 0.22512    f1 : 0.80076\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 89s/6110s\n",
      "TRAIN    loss : 1.18630    f1 : 0.17759\n",
      "Val    loss : 0.61709    f1 : 0.24924\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 89s/6046s\n",
      "TRAIN    loss : 0.55283    f1 : 0.33802\n",
      "Val    loss : 0.49690    f1 : 0.37232\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 89s/5959s\n",
      "TRAIN    loss : 0.38956    f1 : 0.49489\n",
      "Val    loss : 0.36873    f1 : 0.51222\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 89s/5867s\n",
      "TRAIN    loss : 0.28032    f1 : 0.65696\n",
      "Val    loss : 0.24726    f1 : 0.58036\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 89s/5779s\n",
      "TRAIN    loss : 0.19692    f1 : 0.72892\n",
      "Val    loss : 0.24154    f1 : 0.59098\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 89s/5690s\n",
      "TRAIN    loss : 0.16331    f1 : 0.79967\n",
      "Val    loss : 0.22316    f1 : 0.65449\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/70    time : 89s/5593s\n",
      "TRAIN    loss : 0.13651    f1 : 0.82172\n",
      "Val    loss : 0.22806    f1 : 0.67263\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/70    time : 88s/5483s\n",
      "TRAIN    loss : 0.11608    f1 : 0.86037\n",
      "Val    loss : 0.16638    f1 : 0.78362\n",
      "epoch : 9/70    time : 88s/5388s\n",
      "TRAIN    loss : 0.07671    f1 : 0.90958\n",
      "Val    loss : 0.17024    f1 : 0.74526\n",
      "epoch : 10/70    time : 88s/5301s\n",
      "TRAIN    loss : 0.06936    f1 : 0.90505\n",
      "Val    loss : 0.17447    f1 : 0.76392\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/70    time : 89s/5243s\n",
      "TRAIN    loss : 0.06522    f1 : 0.92817\n",
      "Val    loss : 0.19233    f1 : 0.78989\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/70    time : 89s/5156s\n",
      "TRAIN    loss : 0.05765    f1 : 0.93856\n",
      "Val    loss : 0.17331    f1 : 0.79760\n",
      "epoch : 13/70    time : 88s/5032s\n",
      "TRAIN    loss : 0.05088    f1 : 0.94543\n",
      "Val    loss : 0.15909    f1 : 0.79674\n",
      "epoch : 14/70    time : 88s/4953s\n",
      "TRAIN    loss : 0.02650    f1 : 0.97071\n",
      "Val    loss : 0.15508    f1 : 0.79030\n",
      "epoch : 15/70    time : 88s/4855s\n",
      "TRAIN    loss : 0.05200    f1 : 0.94349\n",
      "Val    loss : 0.17434    f1 : 0.77864\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/70    time : 88s/4775s\n",
      "TRAIN    loss : 0.04390    f1 : 0.95196\n",
      "Val    loss : 0.13759    f1 : 0.81410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 17/70    time : 88s/4682s\n",
      "TRAIN    loss : 0.03270    f1 : 0.97270\n",
      "Val    loss : 0.18340    f1 : 0.79968\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/70    time : 89s/4620s\n",
      "TRAIN    loss : 0.03395    f1 : 0.97581\n",
      "Val    loss : 0.17472    f1 : 0.81904\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/70    time : 89s/4526s\n",
      "TRAIN    loss : 0.02126    f1 : 0.97604\n",
      "Val    loss : 0.15110    f1 : 0.81920\n",
      "-----------------SAVE:20 epoch----------------\n",
      "epoch : 20/70    time : 89s/4433s\n",
      "TRAIN    loss : 0.01831    f1 : 0.97892\n",
      "Val    loss : 0.12764    f1 : 0.83933\n",
      "epoch : 21/70    time : 88s/4332s\n",
      "TRAIN    loss : 0.03247    f1 : 0.96159\n",
      "Val    loss : 0.19551    f1 : 0.76485\n",
      "epoch : 22/70    time : 88s/4229s\n",
      "TRAIN    loss : 0.04353    f1 : 0.95430\n",
      "Val    loss : 0.19120    f1 : 0.78784\n",
      "epoch : 23/70    time : 88s/4155s\n",
      "TRAIN    loss : 0.02937    f1 : 0.96254\n",
      "Val    loss : 0.18549    f1 : 0.78082\n",
      "-----------------SAVE:24 epoch----------------\n",
      "epoch : 24/70    time : 89s/4088s\n",
      "TRAIN    loss : 0.03571    f1 : 0.95757\n",
      "Val    loss : 0.14766    f1 : 0.84434\n",
      "epoch : 25/70    time : 88s/3955s\n",
      "TRAIN    loss : 0.01567    f1 : 0.98583\n",
      "Val    loss : 0.14813    f1 : 0.79916\n",
      "epoch : 26/70    time : 88s/3871s\n",
      "TRAIN    loss : 0.02131    f1 : 0.98240\n",
      "Val    loss : 0.14339    f1 : 0.80562\n",
      "epoch : 27/70    time : 88s/3793s\n",
      "TRAIN    loss : 0.01485    f1 : 0.98163\n",
      "Val    loss : 0.15967    f1 : 0.82839\n",
      "epoch : 28/70    time : 88s/3706s\n",
      "TRAIN    loss : 0.02001    f1 : 0.98595\n",
      "Val    loss : 0.14875    f1 : 0.84175\n",
      "epoch : 29/70    time : 88s/3618s\n",
      "TRAIN    loss : 0.02243    f1 : 0.97847\n",
      "Val    loss : 0.23037    f1 : 0.83839\n",
      "epoch : 30/70    time : 88s/3532s\n",
      "TRAIN    loss : 0.02588    f1 : 0.97806\n",
      "Val    loss : 0.19594    f1 : 0.77799\n",
      "epoch : 31/70    time : 88s/3444s\n",
      "TRAIN    loss : 0.03285    f1 : 0.96526\n",
      "Val    loss : 0.14030    f1 : 0.79881\n",
      "epoch : 32/70    time : 88s/3352s\n",
      "TRAIN    loss : 0.01261    f1 : 0.98301\n",
      "Val    loss : 0.16426    f1 : 0.81028\n",
      "epoch : 33/70    time : 88s/3264s\n",
      "TRAIN    loss : 0.00975    f1 : 0.99093\n",
      "Val    loss : 0.17503    f1 : 0.79752\n",
      "-----------------SAVE:34 epoch----------------\n",
      "epoch : 34/70    time : 89s/3188s\n",
      "TRAIN    loss : 0.00554    f1 : 0.99594\n",
      "Val    loss : 0.18683    f1 : 0.84767\n",
      "epoch : 35/70    time : 88s/3085s\n",
      "TRAIN    loss : 0.01090    f1 : 0.98679\n",
      "Val    loss : 0.19579    f1 : 0.80304\n",
      "epoch : 36/70    time : 88s/2992s\n",
      "TRAIN    loss : 0.01546    f1 : 0.98580\n",
      "Val    loss : 0.16520    f1 : 0.79564\n",
      "epoch : 37/70    time : 88s/2906s\n",
      "TRAIN    loss : 0.01397    f1 : 0.98511\n",
      "Val    loss : 0.17434    f1 : 0.83811\n",
      "epoch : 38/70    time : 88s/2822s\n",
      "TRAIN    loss : 0.01495    f1 : 0.99175\n",
      "Val    loss : 0.18954    f1 : 0.83510\n",
      "epoch : 39/70    time : 88s/2734s\n",
      "TRAIN    loss : 0.02147    f1 : 0.97871\n",
      "Val    loss : 0.21392    f1 : 0.80530\n",
      "epoch : 40/70    time : 88s/2637s\n",
      "TRAIN    loss : 0.01158    f1 : 0.98729\n",
      "Val    loss : 0.15966    f1 : 0.82361\n",
      "epoch : 41/70    time : 88s/2558s\n",
      "TRAIN    loss : 0.01064    f1 : 0.99101\n",
      "Val    loss : 0.20503    f1 : 0.77995\n",
      "epoch : 42/70    time : 88s/2472s\n",
      "TRAIN    loss : 0.02532    f1 : 0.98168\n",
      "Val    loss : 0.18008    f1 : 0.82052\n",
      "-----------------SAVE:43 epoch----------------\n",
      "epoch : 43/70    time : 89s/2396s\n",
      "TRAIN    loss : 0.02777    f1 : 0.97780\n",
      "Val    loss : 0.19883    f1 : 0.85759\n",
      "epoch : 44/70    time : 88s/2295s\n",
      "TRAIN    loss : 0.01345    f1 : 0.98491\n",
      "Val    loss : 0.18151    f1 : 0.83086\n",
      "epoch : 45/70    time : 88s/2202s\n",
      "TRAIN    loss : 0.01265    f1 : 0.99101\n",
      "Val    loss : 0.19817    f1 : 0.80235\n",
      "epoch : 46/70    time : 88s/2118s\n",
      "TRAIN    loss : 0.02247    f1 : 0.97206\n",
      "Val    loss : 0.25973    f1 : 0.78749\n",
      "epoch : 47/70    time : 88s/2034s\n",
      "TRAIN    loss : 0.03890    f1 : 0.95454\n",
      "Val    loss : 0.16920    f1 : 0.79026\n",
      "epoch : 48/70    time : 88s/1943s\n",
      "TRAIN    loss : 0.04568    f1 : 0.96290\n",
      "Val    loss : 0.20158    f1 : 0.80666\n",
      "epoch : 49/70    time : 88s/1855s\n",
      "TRAIN    loss : 0.01691    f1 : 0.98342\n",
      "Val    loss : 0.17492    f1 : 0.83416\n",
      "epoch : 50/70    time : 88s/1764s\n",
      "TRAIN    loss : 0.01999    f1 : 0.97474\n",
      "Val    loss : 0.22409    f1 : 0.78480\n",
      "epoch : 51/70    time : 88s/1672s\n",
      "TRAIN    loss : 0.01429    f1 : 0.98693\n",
      "Val    loss : 0.16155    f1 : 0.80707\n",
      "epoch : 52/70    time : 88s/1585s\n",
      "TRAIN    loss : 0.00982    f1 : 0.99005\n",
      "Val    loss : 0.18114    f1 : 0.82551\n",
      "epoch : 53/70    time : 88s/1492s\n",
      "TRAIN    loss : 0.00778    f1 : 0.98604\n",
      "Val    loss : 0.19102    f1 : 0.82562\n",
      "epoch : 54/70    time : 88s/1412s\n",
      "TRAIN    loss : 0.01590    f1 : 0.98947\n",
      "Val    loss : 0.19105    f1 : 0.81748\n",
      "epoch : 55/70    time : 88s/1322s\n",
      "TRAIN    loss : 0.01379    f1 : 0.98899\n",
      "Val    loss : 0.14343    f1 : 0.82544\n",
      "epoch : 56/70    time : 88s/1233s\n",
      "TRAIN    loss : 0.00784    f1 : 0.99305\n",
      "Val    loss : 0.22367    f1 : 0.83379\n",
      "-----------------SAVE:57 epoch----------------\n",
      "epoch : 57/70    time : 89s/1151s\n",
      "TRAIN    loss : 0.01473    f1 : 0.99040\n",
      "Val    loss : 0.13407    f1 : 0.87262\n",
      "epoch : 58/70    time : 88s/1058s\n",
      "TRAIN    loss : 0.00951    f1 : 0.98646\n",
      "Val    loss : 0.22894    f1 : 0.81558\n",
      "epoch : 59/70    time : 88s/969s\n",
      "TRAIN    loss : 0.01482    f1 : 0.98708\n",
      "Val    loss : 0.21760    f1 : 0.82370\n",
      "epoch : 60/70    time : 88s/882s\n",
      "TRAIN    loss : 0.01114    f1 : 0.99638\n",
      "Val    loss : 0.17414    f1 : 0.83667\n",
      "epoch : 61/70    time : 88s/793s\n",
      "TRAIN    loss : 0.00170    f1 : 0.99864\n",
      "Val    loss : 0.17818    f1 : 0.84612\n",
      "epoch : 62/70    time : 88s/705s\n",
      "TRAIN    loss : 0.01954    f1 : 0.98390\n",
      "Val    loss : 0.20111    f1 : 0.81878\n",
      "epoch : 63/70    time : 88s/618s\n",
      "TRAIN    loss : 0.00959    f1 : 0.98997\n",
      "Val    loss : 0.18830    f1 : 0.80987\n",
      "epoch : 64/70    time : 88s/529s\n",
      "TRAIN    loss : 0.00585    f1 : 0.99736\n",
      "Val    loss : 0.22922    f1 : 0.84025\n",
      "epoch : 65/70    time : 88s/440s\n",
      "TRAIN    loss : 0.00489    f1 : 0.99546\n",
      "Val    loss : 0.18423    f1 : 0.82999\n",
      "epoch : 66/70    time : 88s/352s\n",
      "TRAIN    loss : 0.00698    f1 : 0.98813\n",
      "Val    loss : 0.15982    f1 : 0.85037\n",
      "epoch : 67/70    time : 88s/264s\n",
      "TRAIN    loss : 0.01160    f1 : 0.98987\n",
      "Val    loss : 0.19785    f1 : 0.84576\n",
      "epoch : 68/70    time : 88s/176s\n",
      "TRAIN    loss : 0.01663    f1 : 0.99068\n",
      "Val    loss : 0.20280    f1 : 0.82246\n",
      "epoch : 69/70    time : 88s/88s\n",
      "TRAIN    loss : 0.03169    f1 : 0.98191\n",
      "Val    loss : 0.21459    f1 : 0.79919\n",
      "epoch : 70/70    time : 88s/0s\n",
      "TRAIN    loss : 0.02757    f1 : 0.98539\n",
      "Val    loss : 0.20580    f1 : 0.79526\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 94s/6489s\n",
      "TRAIN    loss : 1.19605    f1 : 0.16904\n",
      "Val    loss : 0.63379    f1 : 0.22676\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 89s/6058s\n",
      "TRAIN    loss : 0.56203    f1 : 0.33050\n",
      "Val    loss : 0.42872    f1 : 0.42872\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 89s/5944s\n",
      "TRAIN    loss : 0.39558    f1 : 0.49273\n",
      "Val    loss : 0.37966    f1 : 0.50071\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 89s/5870s\n",
      "TRAIN    loss : 0.28659    f1 : 0.60968\n",
      "Val    loss : 0.24183    f1 : 0.61061\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 89s/5786s\n",
      "TRAIN    loss : 0.21027    f1 : 0.71638\n",
      "Val    loss : 0.19477    f1 : 0.63841\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 89s/5695s\n",
      "TRAIN    loss : 0.15740    f1 : 0.80654\n",
      "Val    loss : 0.18183    f1 : 0.73124\n",
      "epoch : 7/70    time : 88s/5572s\n",
      "TRAIN    loss : 0.09962    f1 : 0.87375\n",
      "Val    loss : 0.17962    f1 : 0.69440\n",
      "epoch : 8/70    time : 88s/5467s\n",
      "TRAIN    loss : 0.10623    f1 : 0.87071\n",
      "Val    loss : 0.15732    f1 : 0.71268\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/70    time : 89s/5416s\n",
      "TRAIN    loss : 0.07579    f1 : 0.91275\n",
      "Val    loss : 0.18369    f1 : 0.76849\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/70    time : 89s/5335s\n",
      "TRAIN    loss : 0.07444    f1 : 0.91168\n",
      "Val    loss : 0.15837    f1 : 0.77728\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/70    time : 89s/5237s\n",
      "TRAIN    loss : 0.05143    f1 : 0.93471\n",
      "Val    loss : 0.14620    f1 : 0.78552\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/70    time : 89s/5154s\n",
      "TRAIN    loss : 0.04618    f1 : 0.95693\n",
      "Val    loss : 0.11178    f1 : 0.80199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/70    time : 89s/5062s\n",
      "TRAIN    loss : 0.03150    f1 : 0.96227\n",
      "Val    loss : 0.11262    f1 : 0.81828\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/70    time : 89s/4971s\n",
      "TRAIN    loss : 0.03996    f1 : 0.96178\n",
      "Val    loss : 0.12356    f1 : 0.83326\n",
      "epoch : 15/70    time : 88s/4854s\n",
      "TRAIN    loss : 0.02774    f1 : 0.97049\n",
      "Val    loss : 0.12104    f1 : 0.80379\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/70    time : 89s/4795s\n",
      "TRAIN    loss : 0.02934    f1 : 0.96730\n",
      "Val    loss : 0.10654    f1 : 0.86568\n",
      "epoch : 17/70    time : 88s/4678s\n",
      "TRAIN    loss : 0.03577    f1 : 0.96355\n",
      "Val    loss : 0.10525    f1 : 0.83270\n",
      "epoch : 18/70    time : 88s/4579s\n",
      "TRAIN    loss : 0.03424    f1 : 0.95866\n",
      "Val    loss : 0.15297    f1 : 0.84158\n",
      "epoch : 19/70    time : 88s/4506s\n",
      "TRAIN    loss : 0.03525    f1 : 0.95924\n",
      "Val    loss : 0.14184    f1 : 0.81713\n",
      "epoch : 20/70    time : 88s/4413s\n",
      "TRAIN    loss : 0.03535    f1 : 0.95188\n",
      "Val    loss : 0.13353    f1 : 0.83050\n",
      "epoch : 21/70    time : 88s/4326s\n",
      "TRAIN    loss : 0.02522    f1 : 0.97777\n",
      "Val    loss : 0.11676    f1 : 0.84080\n",
      "epoch : 22/70    time : 85s/4085s\n",
      "TRAIN    loss : 0.01750    f1 : 0.98524\n",
      "Val    loss : 0.15683    f1 : 0.79058\n",
      "epoch : 23/70    time : 83s/3908s\n",
      "TRAIN    loss : 0.02081    f1 : 0.97021\n",
      "Val    loss : 0.11788    f1 : 0.81550\n",
      "epoch : 24/70    time : 83s/3838s\n",
      "TRAIN    loss : 0.02833    f1 : 0.97099\n",
      "Val    loss : 0.13602    f1 : 0.81333\n",
      "epoch : 25/70    time : 85s/3812s\n",
      "TRAIN    loss : 0.02268    f1 : 0.98336\n",
      "Val    loss : 0.14761    f1 : 0.85593\n",
      "epoch : 26/70    time : 87s/3838s\n",
      "TRAIN    loss : 0.01583    f1 : 0.98705\n",
      "Val    loss : 0.14188    f1 : 0.82674\n",
      "epoch : 27/70    time : 88s/3788s\n",
      "TRAIN    loss : 0.02019    f1 : 0.97871\n",
      "Val    loss : 0.14929    f1 : 0.79338\n",
      "epoch : 28/70    time : 88s/3703s\n",
      "TRAIN    loss : 0.01727    f1 : 0.98622\n",
      "Val    loss : 0.14108    f1 : 0.80814\n",
      "epoch : 29/70    time : 88s/3617s\n",
      "TRAIN    loss : 0.02267    f1 : 0.98583\n",
      "Val    loss : 0.19252    f1 : 0.74742\n",
      "epoch : 30/70    time : 88s/3529s\n",
      "TRAIN    loss : 0.01762    f1 : 0.98591\n",
      "Val    loss : 0.18466    f1 : 0.81298\n",
      "epoch : 31/70    time : 88s/3436s\n",
      "TRAIN    loss : 0.01547    f1 : 0.98249\n",
      "Val    loss : 0.15101    f1 : 0.83412\n",
      "epoch : 32/70    time : 88s/3340s\n",
      "TRAIN    loss : 0.02015    f1 : 0.97912\n",
      "Val    loss : 0.19049    f1 : 0.77584\n",
      "epoch : 33/70    time : 88s/3263s\n",
      "TRAIN    loss : 0.02442    f1 : 0.97000\n",
      "Val    loss : 0.16254    f1 : 0.79092\n",
      "epoch : 34/70    time : 88s/3176s\n",
      "TRAIN    loss : 0.01537    f1 : 0.98056\n",
      "Val    loss : 0.20872    f1 : 0.81090\n",
      "epoch : 35/70    time : 88s/3089s\n",
      "TRAIN    loss : 0.02554    f1 : 0.97397\n",
      "Val    loss : 0.16663    f1 : 0.80886\n",
      "epoch : 36/70    time : 88s/2998s\n",
      "TRAIN    loss : 0.01829    f1 : 0.97987\n",
      "Val    loss : 0.15770    f1 : 0.81391\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 88s/6106s\n",
      "TRAIN    loss : 1.20028    f1 : 0.16522\n",
      "Val    loss : 0.56865    f1 : 0.25474\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 89s/6034s\n",
      "TRAIN    loss : 0.56127    f1 : 0.35062\n",
      "Val    loss : 0.42802    f1 : 0.43143\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 89s/5943s\n",
      "TRAIN    loss : 0.40560    f1 : 0.51667\n",
      "Val    loss : 0.33185    f1 : 0.52892\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 89s/5847s\n",
      "TRAIN    loss : 0.28402    f1 : 0.62530\n",
      "Val    loss : 0.23482    f1 : 0.60373\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 89s/5756s\n",
      "TRAIN    loss : 0.20961    f1 : 0.72903\n",
      "Val    loss : 0.25855    f1 : 0.64509\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 89s/5668s\n",
      "TRAIN    loss : 0.16348    f1 : 0.78981\n",
      "Val    loss : 0.16323    f1 : 0.71249\n",
      "epoch : 7/70    time : 88s/5557s\n",
      "TRAIN    loss : 0.11803    f1 : 0.85553\n",
      "Val    loss : 0.21592    f1 : 0.69250\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/70    time : 89s/5487s\n",
      "TRAIN    loss : 0.10838    f1 : 0.85287\n",
      "Val    loss : 0.14368    f1 : 0.77987\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/70    time : 89s/5406s\n",
      "TRAIN    loss : 0.08337    f1 : 0.88307\n",
      "Val    loss : 0.15007    f1 : 0.79808\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/70    time : 88s/5309s\n",
      "TRAIN    loss : 0.07379    f1 : 0.92020\n",
      "Val    loss : 0.13686    f1 : 0.80963\n",
      "epoch : 11/70    time : 88s/5199s\n",
      "TRAIN    loss : 0.05787    f1 : 0.92817\n",
      "Val    loss : 0.22265    f1 : 0.75374\n",
      "epoch : 12/70    time : 88s/5108s\n",
      "TRAIN    loss : 0.04459    f1 : 0.96174\n",
      "Val    loss : 0.15413    f1 : 0.79629\n",
      "epoch : 13/70    time : 88s/5027s\n",
      "TRAIN    loss : 0.05517    f1 : 0.94455\n",
      "Val    loss : 0.13759    f1 : 0.80414\n",
      "epoch : 14/70    time : 88s/4928s\n",
      "TRAIN    loss : 0.06040    f1 : 0.93471\n",
      "Val    loss : 0.15225    f1 : 0.75954\n",
      "epoch : 15/70    time : 88s/4821s\n",
      "TRAIN    loss : 0.04631    f1 : 0.95160\n",
      "Val    loss : 0.16028    f1 : 0.80676\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/70    time : 88s/4764s\n",
      "TRAIN    loss : 0.03617    f1 : 0.95872\n",
      "Val    loss : 0.14549    f1 : 0.81272\n",
      "-----------------SAVE:17 epoch----------------\n",
      "epoch : 17/70    time : 88s/4689s\n",
      "TRAIN    loss : 0.02833    f1 : 0.96539\n",
      "Val    loss : 0.16293    f1 : 0.83409\n",
      "epoch : 18/70    time : 88s/4576s\n",
      "TRAIN    loss : 0.02245    f1 : 0.97716\n",
      "Val    loss : 0.21412    f1 : 0.83030\n",
      "epoch : 19/70    time : 88s/4473s\n",
      "TRAIN    loss : 0.02247    f1 : 0.97617\n",
      "Val    loss : 0.16930    f1 : 0.82724\n",
      "epoch : 20/70    time : 88s/4391s\n",
      "TRAIN    loss : 0.01877    f1 : 0.97791\n",
      "Val    loss : 0.19612    f1 : 0.77163\n",
      "epoch : 21/70    time : 88s/4302s\n",
      "TRAIN    loss : 0.02561    f1 : 0.96582\n",
      "Val    loss : 0.17263    f1 : 0.80539\n",
      "epoch : 22/70    time : 88s/4220s\n",
      "TRAIN    loss : 0.02281    f1 : 0.97571\n",
      "Val    loss : 0.15459    f1 : 0.79662\n",
      "-----------------SAVE:23 epoch----------------\n",
      "epoch : 23/70    time : 88s/4149s\n",
      "TRAIN    loss : 0.02192    f1 : 0.97942\n",
      "Val    loss : 0.14560    f1 : 0.84066\n",
      "epoch : 24/70    time : 88s/4042s\n",
      "TRAIN    loss : 0.04299    f1 : 0.95991\n",
      "Val    loss : 0.13647    f1 : 0.80952\n",
      "epoch : 25/70    time : 88s/3949s\n",
      "TRAIN    loss : 0.02485    f1 : 0.97187\n",
      "Val    loss : 0.17865    f1 : 0.76960\n",
      "epoch : 26/70    time : 88s/3869s\n",
      "TRAIN    loss : 0.02805    f1 : 0.96482\n",
      "Val    loss : 0.33912    f1 : 0.81353\n",
      "-----------------SAVE:27 epoch----------------\n",
      "epoch : 27/70    time : 88s/3797s\n",
      "TRAIN    loss : 0.01597    f1 : 0.98653\n",
      "Val    loss : 0.16744    f1 : 0.84209\n",
      "epoch : 28/70    time : 88s/3683s\n",
      "TRAIN    loss : 0.02037    f1 : 0.98086\n",
      "Val    loss : 0.18858    f1 : 0.82162\n",
      "epoch : 29/70    time : 88s/3603s\n",
      "TRAIN    loss : 0.02609    f1 : 0.96439\n",
      "Val    loss : 0.18471    f1 : 0.82537\n",
      "-----------------SAVE:30 epoch----------------\n",
      "epoch : 30/70    time : 88s/3529s\n",
      "TRAIN    loss : 0.02359    f1 : 0.98097\n",
      "Val    loss : 0.12911    f1 : 0.87172\n",
      "epoch : 31/70    time : 88s/3424s\n",
      "TRAIN    loss : 0.01493    f1 : 0.98636\n",
      "Val    loss : 0.12514    f1 : 0.84188\n",
      "epoch : 32/70    time : 88s/3336s\n",
      "TRAIN    loss : 0.01816    f1 : 0.98222\n",
      "Val    loss : 0.12063    f1 : 0.82443\n",
      "epoch : 33/70    time : 88s/3244s\n",
      "TRAIN    loss : 0.01242    f1 : 0.99286\n",
      "Val    loss : 0.18375    f1 : 0.81190\n",
      "epoch : 34/70    time : 88s/3154s\n",
      "TRAIN    loss : 0.02377    f1 : 0.98260\n",
      "Val    loss : 0.15154    f1 : 0.80837\n",
      "epoch : 35/70    time : 88s/3073s\n",
      "TRAIN    loss : 0.04347    f1 : 0.96107\n",
      "Val    loss : 0.18605    f1 : 0.77467\n",
      "epoch : 36/70    time : 88s/2990s\n",
      "TRAIN    loss : 0.03109    f1 : 0.96960\n",
      "Val    loss : 0.16780    f1 : 0.76027\n",
      "epoch : 37/70    time : 88s/2898s\n",
      "TRAIN    loss : 0.01533    f1 : 0.98251\n",
      "Val    loss : 0.14667    f1 : 0.79025\n",
      "epoch : 38/70    time : 88s/2806s\n",
      "TRAIN    loss : 0.02290    f1 : 0.97955\n",
      "Val    loss : 0.17501    f1 : 0.79324\n",
      "epoch : 39/70    time : 88s/2719s\n",
      "TRAIN    loss : 0.01264    f1 : 0.98420\n",
      "Val    loss : 0.17250    f1 : 0.80397\n",
      "epoch : 40/70    time : 88s/2627s\n",
      "TRAIN    loss : 0.01081    f1 : 0.98397\n",
      "Val    loss : 0.18351    f1 : 0.82323\n",
      "epoch : 41/70    time : 88s/2543s\n",
      "TRAIN    loss : 0.01748    f1 : 0.98163\n",
      "Val    loss : 0.18033    f1 : 0.80554\n",
      "epoch : 42/70    time : 88s/2463s\n",
      "TRAIN    loss : 0.00792    f1 : 0.99447\n",
      "Val    loss : 0.18247    f1 : 0.79867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 43/70    time : 88s/2371s\n",
      "TRAIN    loss : 0.00376    f1 : 0.99704\n",
      "Val    loss : 0.17664    f1 : 0.79670\n",
      "epoch : 44/70    time : 88s/2279s\n",
      "TRAIN    loss : 0.00359    f1 : 0.99582\n",
      "Val    loss : 0.16457    f1 : 0.79994\n",
      "epoch : 45/70    time : 88s/2192s\n",
      "TRAIN    loss : 0.00872    f1 : 0.99014\n",
      "Val    loss : 0.14488    f1 : 0.81839\n",
      "epoch : 46/70    time : 88s/2105s\n",
      "TRAIN    loss : 0.02030    f1 : 0.97969\n",
      "Val    loss : 0.14038    f1 : 0.81386\n",
      "epoch : 47/70    time : 88s/2019s\n",
      "TRAIN    loss : 0.02177    f1 : 0.97960\n",
      "Val    loss : 0.16513    f1 : 0.83227\n",
      "epoch : 48/70    time : 88s/1932s\n",
      "TRAIN    loss : 0.02002    f1 : 0.98463\n",
      "Val    loss : 0.17121    f1 : 0.78402\n",
      "epoch : 49/70    time : 88s/1846s\n",
      "TRAIN    loss : 0.01662    f1 : 0.98332\n",
      "Val    loss : 0.14186    f1 : 0.82319\n",
      "epoch : 50/70    time : 88s/1756s\n",
      "TRAIN    loss : 0.01315    f1 : 0.98577\n",
      "Val    loss : 0.16602    f1 : 0.82177\n",
      "----------fold_4 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 88s/6101s\n",
      "TRAIN    loss : 1.16616    f1 : 0.17287\n",
      "Val    loss : 0.61864    f1 : 0.28849\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 89s/6036s\n",
      "TRAIN    loss : 0.54753    f1 : 0.33855\n",
      "Val    loss : 0.49804    f1 : 0.35689\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 89s/5942s\n",
      "TRAIN    loss : 0.39555    f1 : 0.50446\n",
      "Val    loss : 0.33719    f1 : 0.51455\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 89s/5863s\n",
      "TRAIN    loss : 0.26905    f1 : 0.66699\n",
      "Val    loss : 0.26479    f1 : 0.62660\n",
      "epoch : 5/70    time : 88s/5740s\n",
      "TRAIN    loss : 0.21366    f1 : 0.70003\n",
      "Val    loss : 0.29625    f1 : 0.60940\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 89s/5677s\n",
      "TRAIN    loss : 0.16638    f1 : 0.78968\n",
      "Val    loss : 0.21631    f1 : 0.68260\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/70    time : 89s/5596s\n",
      "TRAIN    loss : 0.11806    f1 : 0.83705\n",
      "Val    loss : 0.21234    f1 : 0.69718\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/70    time : 89s/5504s\n",
      "TRAIN    loss : 0.07815    f1 : 0.90159\n",
      "Val    loss : 0.22663    f1 : 0.71357\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/70    time : 89s/5410s\n",
      "TRAIN    loss : 0.08957    f1 : 0.90244\n",
      "Val    loss : 0.23018    f1 : 0.78401\n",
      "epoch : 10/70    time : 88s/5296s\n",
      "TRAIN    loss : 0.07228    f1 : 0.91650\n",
      "Val    loss : 0.21091    f1 : 0.72658\n",
      "epoch : 11/70    time : 88s/5201s\n",
      "TRAIN    loss : 0.05873    f1 : 0.91634\n",
      "Val    loss : 0.17404    f1 : 0.75014\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/70    time : 89s/5149s\n",
      "TRAIN    loss : 0.06672    f1 : 0.93250\n",
      "Val    loss : 0.14764    f1 : 0.79721\n",
      "epoch : 13/70    time : 88s/5038s\n",
      "TRAIN    loss : 0.03678    f1 : 0.95943\n",
      "Val    loss : 0.18419    f1 : 0.72220\n",
      "epoch : 14/70    time : 88s/4936s\n",
      "TRAIN    loss : 0.03007    f1 : 0.97011\n",
      "Val    loss : 0.17535    f1 : 0.74856\n",
      "epoch : 15/70    time : 89s/4875s\n",
      "TRAIN    loss : 0.04799    f1 : 0.95683\n",
      "Val    loss : 0.16912    f1 : 0.75288\n",
      "epoch : 16/70    time : 89s/4782s\n",
      "TRAIN    loss : 0.03104    f1 : 0.96708\n",
      "Val    loss : 0.21950    f1 : 0.74578\n",
      "epoch : 17/70    time : 89s/4698s\n",
      "TRAIN    loss : 0.04824    f1 : 0.94177\n",
      "Val    loss : 0.25163    f1 : 0.76955\n",
      "epoch : 18/70    time : 85s/4438s\n",
      "TRAIN    loss : 0.02835    f1 : 0.96824\n",
      "Val    loss : 0.20341    f1 : 0.75541\n",
      "epoch : 19/70    time : 83s/4249s\n",
      "TRAIN    loss : 0.01753    f1 : 0.98114\n",
      "Val    loss : 0.23624    f1 : 0.75333\n",
      "epoch : 20/70    time : 83s/4169s\n",
      "TRAIN    loss : 0.02992    f1 : 0.96666\n",
      "Val    loss : 0.27898    f1 : 0.77565\n",
      "epoch : 21/70    time : 85s/4152s\n",
      "TRAIN    loss : 0.02529    f1 : 0.98398\n",
      "Val    loss : 0.24925    f1 : 0.75829\n",
      "epoch : 22/70    time : 87s/4191s\n",
      "TRAIN    loss : 0.01671    f1 : 0.98023\n",
      "Val    loss : 0.18639    f1 : 0.77373\n",
      "epoch : 23/70    time : 88s/4145s\n",
      "TRAIN    loss : 0.03302    f1 : 0.96849\n",
      "Val    loss : 0.21951    f1 : 0.78504\n",
      "-----------------SAVE:24 epoch----------------\n",
      "epoch : 24/70    time : 89s/4097s\n",
      "TRAIN    loss : 0.03438    f1 : 0.96951\n",
      "Val    loss : 0.19425    f1 : 0.79828\n",
      "epoch : 25/70    time : 89s/3998s\n",
      "TRAIN    loss : 0.03198    f1 : 0.96931\n",
      "Val    loss : 0.25521    f1 : 0.78914\n",
      "epoch : 26/70    time : 89s/3924s\n",
      "TRAIN    loss : 0.03835    f1 : 0.97194\n",
      "Val    loss : 0.29441    f1 : 0.74422\n",
      "-----------------SAVE:27 epoch----------------\n",
      "epoch : 27/70    time : 90s/3859s\n",
      "TRAIN    loss : 0.04199    f1 : 0.95417\n",
      "Val    loss : 0.21423    f1 : 0.82253\n",
      "-----------------SAVE:28 epoch----------------\n",
      "epoch : 28/70    time : 90s/3768s\n",
      "TRAIN    loss : 0.02196    f1 : 0.97969\n",
      "Val    loss : 0.16639    f1 : 0.82730\n",
      "epoch : 29/70    time : 89s/3653s\n",
      "TRAIN    loss : 0.01991    f1 : 0.97398\n",
      "Val    loss : 0.26096    f1 : 0.76176\n",
      "epoch : 30/70    time : 89s/3565s\n",
      "TRAIN    loss : 0.02120    f1 : 0.97072\n",
      "Val    loss : 0.25913    f1 : 0.77432\n",
      "epoch : 31/70    time : 89s/3482s\n",
      "TRAIN    loss : 0.02149    f1 : 0.97512\n",
      "Val    loss : 0.19735    f1 : 0.78236\n",
      "epoch : 32/70    time : 89s/3391s\n",
      "TRAIN    loss : 0.01923    f1 : 0.97659\n",
      "Val    loss : 0.20816    f1 : 0.79171\n",
      "epoch : 33/70    time : 89s/3298s\n",
      "TRAIN    loss : 0.01796    f1 : 0.98008\n",
      "Val    loss : 0.20498    f1 : 0.80761\n",
      "epoch : 34/70    time : 89s/3211s\n",
      "TRAIN    loss : 0.00703    f1 : 0.99509\n",
      "Val    loss : 0.21012    f1 : 0.81522\n",
      "epoch : 35/70    time : 89s/3120s\n",
      "TRAIN    loss : 0.01391    f1 : 0.98564\n",
      "Val    loss : 0.27468    f1 : 0.74906\n",
      "-----------------SAVE:36 epoch----------------\n",
      "epoch : 36/70    time : 90s/3047s\n",
      "TRAIN    loss : 0.02566    f1 : 0.98412\n",
      "Val    loss : 0.17257    f1 : 0.84315\n",
      "epoch : 37/70    time : 89s/2940s\n",
      "TRAIN    loss : 0.01014    f1 : 0.98967\n",
      "Val    loss : 0.33342    f1 : 0.80156\n",
      "epoch : 38/70    time : 89s/2855s\n",
      "TRAIN    loss : 0.02127    f1 : 0.98273\n",
      "Val    loss : 0.19079    f1 : 0.81877\n",
      "epoch : 39/70    time : 89s/2766s\n",
      "TRAIN    loss : 0.01185    f1 : 0.99079\n",
      "Val    loss : 0.18632    f1 : 0.78076\n",
      "epoch : 40/70    time : 89s/2673s\n",
      "TRAIN    loss : 0.01095    f1 : 0.99010\n",
      "Val    loss : 0.21580    f1 : 0.77996\n",
      "epoch : 41/70    time : 89s/2584s\n",
      "TRAIN    loss : 0.00610    f1 : 0.99403\n",
      "Val    loss : 0.22062    f1 : 0.79813\n",
      "epoch : 42/70    time : 89s/2491s\n",
      "TRAIN    loss : 0.00184    f1 : 0.99830\n",
      "Val    loss : 0.21193    f1 : 0.81871\n",
      "epoch : 43/70    time : 89s/2406s\n",
      "TRAIN    loss : 0.01015    f1 : 0.99362\n",
      "Val    loss : 0.24278    f1 : 0.82212\n",
      "epoch : 44/70    time : 89s/2316s\n",
      "TRAIN    loss : 0.00984    f1 : 0.99322\n",
      "Val    loss : 0.22629    f1 : 0.78282\n",
      "-----------------SAVE:45 epoch----------------\n",
      "epoch : 45/70    time : 90s/2238s\n",
      "TRAIN    loss : 0.01554    f1 : 0.98783\n",
      "Val    loss : 0.17932    f1 : 0.84353\n",
      "epoch : 46/70    time : 89s/2132s\n",
      "TRAIN    loss : 0.01453    f1 : 0.98854\n",
      "Val    loss : 0.17233    f1 : 0.83605\n",
      "epoch : 47/70    time : 89s/2044s\n",
      "TRAIN    loss : 0.00848    f1 : 0.98779\n",
      "Val    loss : 0.16659    f1 : 0.83070\n",
      "epoch : 48/70    time : 89s/1956s\n",
      "TRAIN    loss : 0.00497    f1 : 0.99221\n",
      "Val    loss : 0.20233    f1 : 0.82476\n",
      "epoch : 49/70    time : 89s/1869s\n",
      "TRAIN    loss : 0.02106    f1 : 0.99082\n",
      "Val    loss : 0.17475    f1 : 0.83191\n",
      "epoch : 50/70    time : 89s/1787s\n",
      "TRAIN    loss : 0.00979    f1 : 0.98839\n",
      "Val    loss : 0.27431    f1 : 0.83872\n",
      "epoch : 51/70    time : 89s/1696s\n",
      "TRAIN    loss : 0.03177    f1 : 0.97846\n",
      "Val    loss : 0.22553    f1 : 0.78053\n",
      "epoch : 52/70    time : 89s/1610s\n",
      "TRAIN    loss : 0.04538    f1 : 0.95341\n",
      "Val    loss : 0.18571    f1 : 0.81793\n",
      "epoch : 53/70    time : 89s/1515s\n",
      "TRAIN    loss : 0.02984    f1 : 0.96654\n",
      "Val    loss : 0.24732    f1 : 0.75829\n",
      "epoch : 54/70    time : 89s/1427s\n",
      "TRAIN    loss : 0.01277    f1 : 0.98917\n",
      "Val    loss : 0.25829    f1 : 0.82188\n",
      "epoch : 55/70    time : 89s/1339s\n",
      "TRAIN    loss : 0.01373    f1 : 0.98907\n",
      "Val    loss : 0.21762    f1 : 0.79075\n",
      "epoch : 56/70    time : 89s/1251s\n",
      "TRAIN    loss : 0.03198    f1 : 0.96516\n",
      "Val    loss : 0.17163    f1 : 0.80379\n",
      "epoch : 57/70    time : 89s/1160s\n",
      "TRAIN    loss : 0.00928    f1 : 0.98054\n",
      "Val    loss : 0.14932    f1 : 0.79155\n",
      "epoch : 58/70    time : 89s/1071s\n",
      "TRAIN    loss : 0.01148    f1 : 0.98565\n",
      "Val    loss : 0.14830    f1 : 0.79856\n",
      "epoch : 59/70    time : 89s/977s\n",
      "TRAIN    loss : 0.01339    f1 : 0.98955\n",
      "Val    loss : 0.14605    f1 : 0.81270\n",
      "epoch : 60/70    time : 89s/890s\n",
      "TRAIN    loss : 0.01274    f1 : 0.98591\n",
      "Val    loss : 0.19582    f1 : 0.77153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 61/70    time : 89s/799s\n",
      "TRAIN    loss : 0.01115    f1 : 0.99198\n",
      "Val    loss : 0.21695    f1 : 0.79115\n",
      "epoch : 62/70    time : 89s/712s\n",
      "TRAIN    loss : 0.01344    f1 : 0.99295\n",
      "Val    loss : 0.21281    f1 : 0.78018\n",
      "epoch : 63/70    time : 89s/623s\n",
      "TRAIN    loss : 0.01466    f1 : 0.98628\n",
      "Val    loss : 0.31865    f1 : 0.75117\n",
      "epoch : 64/70    time : 89s/535s\n",
      "TRAIN    loss : 0.01711    f1 : 0.98333\n",
      "Val    loss : 0.14645    f1 : 0.82374\n",
      "epoch : 65/70    time : 89s/447s\n",
      "TRAIN    loss : 0.01841    f1 : 0.98278\n",
      "Val    loss : 0.16727    f1 : 0.76778\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022,shuffle=True)\n",
    "batch_size = 32\n",
    "epochs = 70\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay = 2e-2)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2OKpQiO5S1",
    "outputId": "e48def07-ef6d-4325-f297-c705088b3eb8"
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 32\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "seat84vNOOtT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seat84vNOOtT",
    "outputId": "71c853b2-29c3-430e-e4d0-cb1a66e11196"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"data/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"data/submission/b3_norm_epoch70_4_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p87_msjB7L51",
   "metadata": {
    "id": "p87_msjB7L51"
   },
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MW9Fx7QADii5",
   "metadata": {
    "id": "MW9Fx7QADii5"
   },
   "source": [
    "사전 학습 모델의 성능 파악을 할 때 Fold 학습은 실행 시간이 오래걸려서 fold를 나누지 않은 데이터에 대해서 학습을 진행하고 성능을 비교하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "syUpL8e_7L50",
   "metadata": {
    "id": "syUpL8e_7L50"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cJc8Yj7zrh4g",
   "metadata": {
    "id": "cJc8Yj7zrh4g"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "tpCGp41k7L51",
   "metadata": {
    "id": "tpCGp41k7L51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/30    time : 104s/3005s\n",
      "TRAIN    loss : 1.63582    f1 : 0.14407\n",
      "epoch : 2/30    time : 103s/2874s\n",
      "TRAIN    loss : 0.79794    f1 : 0.18042\n",
      "epoch : 3/30    time : 104s/2808s\n",
      "TRAIN    loss : 0.60019    f1 : 0.27673\n",
      "epoch : 4/30    time : 105s/2723s\n",
      "TRAIN    loss : 0.49201    f1 : 0.36683\n",
      "epoch : 5/30    time : 105s/2630s\n",
      "TRAIN    loss : 0.40832    f1 : 0.46088\n",
      "epoch : 6/30    time : 105s/2529s\n",
      "TRAIN    loss : 0.34700    f1 : 0.52105\n",
      "epoch : 7/30    time : 105s/2424s\n",
      "TRAIN    loss : 0.30297    f1 : 0.58867\n",
      "epoch : 8/30    time : 106s/2321s\n",
      "TRAIN    loss : 0.25802    f1 : 0.63940\n",
      "epoch : 9/30    time : 106s/2217s\n",
      "TRAIN    loss : 0.21819    f1 : 0.72477\n",
      "epoch : 10/30    time : 105s/2110s\n",
      "TRAIN    loss : 0.18276    f1 : 0.76222\n",
      "epoch : 11/30    time : 106s/2005s\n",
      "TRAIN    loss : 0.16197    f1 : 0.78331\n",
      "epoch : 12/30    time : 106s/1900s\n",
      "TRAIN    loss : 0.13585    f1 : 0.84183\n",
      "epoch : 13/30    time : 106s/1795s\n",
      "TRAIN    loss : 0.13361    f1 : 0.83834\n",
      "epoch : 14/30    time : 106s/1689s\n",
      "TRAIN    loss : 0.10500    f1 : 0.88052\n",
      "epoch : 15/30    time : 105s/1581s\n",
      "TRAIN    loss : 0.09516    f1 : 0.88641\n",
      "epoch : 16/30    time : 105s/1477s\n",
      "TRAIN    loss : 0.07683    f1 : 0.91670\n",
      "epoch : 17/30    time : 105s/1371s\n",
      "TRAIN    loss : 0.07540    f1 : 0.91288\n",
      "epoch : 18/30    time : 105s/1265s\n",
      "TRAIN    loss : 0.06905    f1 : 0.91904\n",
      "epoch : 19/30    time : 106s/1161s\n",
      "TRAIN    loss : 0.05785    f1 : 0.93932\n",
      "epoch : 20/30    time : 105s/1054s\n",
      "TRAIN    loss : 0.05012    f1 : 0.94496\n",
      "epoch : 21/30    time : 105s/949s\n",
      "TRAIN    loss : 0.04976    f1 : 0.94634\n",
      "epoch : 22/30    time : 105s/844s\n",
      "TRAIN    loss : 0.04322    f1 : 0.95401\n",
      "epoch : 23/30    time : 106s/739s\n",
      "TRAIN    loss : 0.04278    f1 : 0.95974\n",
      "epoch : 24/30    time : 105s/633s\n",
      "TRAIN    loss : 0.03632    f1 : 0.96350\n",
      "epoch : 25/30    time : 105s/527s\n",
      "TRAIN    loss : 0.03161    f1 : 0.97040\n",
      "epoch : 26/30    time : 105s/421s\n",
      "TRAIN    loss : 0.03073    f1 : 0.97570\n",
      "epoch : 27/30    time : 105s/316s\n",
      "TRAIN    loss : 0.02767    f1 : 0.97321\n",
      "epoch : 28/30    time : 105s/211s\n",
      "TRAIN    loss : 0.03039    f1 : 0.96455\n",
      "epoch : 29/30    time : 105s/105s\n",
      "TRAIN    loss : 0.02319    f1 : 0.97945\n",
      "epoch : 30/30    time : 105s/0s\n",
      "TRAIN    loss : 0.02157    f1 : 0.97545\n"
     ]
    }
   ],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YssPW4xq7L53",
   "metadata": {
    "id": "YssPW4xq7L53"
   },
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1w_VB_PY7L53",
   "metadata": {
    "id": "1w_VB_PY7L53"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "pred_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "            pred_prob.extend(pred.detach().cpu().numpy())\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aZMML2u3DTHx",
   "metadata": {
    "id": "aZMML2u3DTHx"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I4io2mJC7L54",
   "metadata": {
    "id": "I4io2mJC7L54"
   },
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "XCV3FEKe7L55",
   "metadata": {
    "id": "XCV3FEKe7L55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"data/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "jsl6tXbz7L56",
   "metadata": {
    "id": "jsl6tXbz7L56"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"data/submission/b3_norm.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ed5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
