{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "594cbadd",
   "metadata": {},
   "source": [
    "## TFRecord_0502 학습\n",
    "\n",
    "- train, valid 를 2:1 로 file을 만들어 전체 TFRecord로 만듬\n",
    "- 전처리, 증식 하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "############### Parameter\n",
    "# NUM_OF_TFRECORDS = 100 # 종류별 TFRecord의 개수\n",
    "BUFFER_SIZE = 16     # 데이터 shuffle을 위한 buffer size\n",
    "BATCH_SIZE = 8       # 배치 사이즈. 한번에 가져오는 이미지 데이터 개수 \n",
    "NUM_CLASS = 88        # class의 개수. binary인 경우는 필요없으며 categorical인 경우 설정\n",
    "IMAGE_SIZE = 150       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d119294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 필요한 DataSet 준비(여러개의 tfrecord 처리)\n",
    "\n",
    "# train, validation TFRecord 폴더 경로(여러개의 tfrecord 처리)\n",
    "# 폴더를 나누고 파일을 복사하는건 수동으로 처리\n",
    "train_tfrecords = './data/class_tf/train_0502.tfrecords'\n",
    "valid_tfrecords = './data/class_tf/valid_0502.tfrecords'\n",
    "\n",
    "# 읽어들인 TFRecord를 다음의 형태(dict)로 변환하는 함수\n",
    "# <ParallelMapDataset shapes: {id: (), image_raw: (), label: ()}, \n",
    "#                     types: {id: tf.string, image_raw: tf.string, label: tf.int64}>\n",
    "def _parse_image_function(example_proto):\n",
    "    # TFRecord를 읽어서 데이터를 복원하기 위한 자료구조.\n",
    "    image_feature_description = {\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/channel': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/filename': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    return tf.io.parse_single_example(example_proto, \n",
    "                                      image_feature_description)\n",
    "\n",
    "# 위에서 얻은 ParallelMapDataset를 다음의 형태(shape)로 변환하는 함수\n",
    "# <ParallelMapDataset shapes: ((None, None, 3), ()), types: (tf.float32, tf.int64)>\n",
    "def map_func(target_record):      \n",
    "    img = target_record['image/image_raw']\n",
    "    label = target_record['image/label']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)    \n",
    "    return img, label\n",
    "\n",
    "\n",
    "# 전처리(normalization & resize) 함수\n",
    "# 이미지 데이터 normalization\n",
    "# 우리예제는 TFRecord 생성 시 원본 size로 저장했기 때문에 image resize를 해야함.\n",
    "def image_preprocess_func(image, label):\n",
    "    result_image = image / 255\n",
    "    result_image = tf.image.resize(result_image, \n",
    "                                   (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                   antialias=False)   \n",
    "    return result_image, label\n",
    "\n",
    "\n",
    "# 만약 multinomial classification이면 one_hot처리도 필요함.\n",
    "def image_postprocess_func(image, label):\n",
    "    onehot_label = tf.one_hot(label, depth=88)    # binary인 경우 one_hot 사용안함.    \n",
    "    return image, label\n",
    "\n",
    "def make_dataset(tfrecords_path, is_train):\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(tfrecords_path)\n",
    "\n",
    "    dataset = dataset.map(_parse_image_function,\n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.map(map_func,\n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # TFRecord로 만들때 섞었음\n",
    "#     if is_train:\n",
    "#         dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "    dataset = dataset.map(image_preprocess_func,\n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.map(image_postprocess_func,\n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca6483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF2_20] *",
   "language": "python",
   "name": "conda-env-machine_TF2_20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
