{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "NWm2EDuv4sCg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19488,
     "status": "ok",
     "timestamp": 1652399878775,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "NWm2EDuv4sCg",
    "outputId": "853e895d-752b-45eb-ace5-30bd57350471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "SvMP8rdQ42W2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3697,
     "status": "ok",
     "timestamp": 1652399888579,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "SvMP8rdQ42W2",
    "outputId": "9169db97-399d-45a5-c6dc-52bf9abb32b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▊                               | 10 kB 32.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 20 kB 40.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 30 kB 44.0 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 40 kB 33.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 51 kB 31.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 61 kB 35.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 71 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 81 kB 30.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 92 kB 32.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 102 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 112 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 122 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 133 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 143 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 153 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 163 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 174 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 184 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 194 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 204 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 215 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 225 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 235 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 245 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 256 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 266 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 276 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 286 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 296 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 307 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 317 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 327 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 337 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 348 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 358 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 368 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 378 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 389 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 399 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 409 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 419 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 430 kB 34.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 431 kB 34.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "executionInfo": {
     "elapsed": 5444,
     "status": "ok",
     "timestamp": 1652399900429,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1652399900430,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1652399900431,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "# train_png = sorted(glob(path + 'data/train/*.png'))\n",
    "# test_png = sorted(glob(path + 'data/test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1652399900431,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "atSgPJRn-OCW"
   },
   "outputs": [],
   "source": [
    "# len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "executionInfo": {
     "elapsed": 767,
     "status": "ok",
     "timestamp": 1652399901194,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"data/train_df.csv\")\n",
    "\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]\n",
    "\n",
    "train_classes = train_y['class']\n",
    "\n",
    "class_unique = sorted(np.unique(train_classes))\n",
    "class_unique = {key:value for key,value in zip(class_unique, range(len(class_unique)))}\n",
    "\n",
    "train_classes = [class_unique[k] for k in train_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1652399903979,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4277/4277 [02:04<00:00, 34.43it/s]\n",
      "100%|███████████████████████████████████████| 2154/2154 [01:02<00:00, 34.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "# test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "# np.save(path + 'data/train_imgs_384', np.array(train_imgs))\n",
    "# np.save(path + 'data/test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "executionInfo": {
     "elapsed": 32725,
     "status": "ok",
     "timestamp": 1652399939127,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'data/train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'data/test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sscGLiJKPy6H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51692,
     "status": "ok",
     "timestamp": 1652399990814,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "sscGLiJKPy6H",
    "outputId": "b639352f-405c-419f-9f77-c9ddde5d0d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.4330380901867049 0.4034575319032911 0.39415050509784405\n",
      "train 표준편차 0.1815717110252788 0.17403455556798705 0.16323395055036488\n"
     ]
    }
   ],
   "source": [
    "# meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "# stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "# meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "# meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "# meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "# stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "# stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "# stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "# print(\"train 평균\",meanR, meanG, meanB)\n",
    "# print(\"train 표준편차\",stdR, stdG, stdB)\n",
    "\n",
    "# train 평균 0.4330380901867049 0.4034575319032911 0.39415050509784405\n",
    "# train 표준편차 0.1815717110252788 0.17403455556798705 0.16323395055036488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "JwVIQCrUSCFE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26484,
     "status": "ok",
     "timestamp": 1652400017289,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "JwVIQCrUSCFE",
    "outputId": "c6f651f3-8c6e-4f6f-d1bf-d0b10a1274fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.41825619520929724 0.3931011906330291 0.386631764639131\n",
      "test 표준편차 0.19505524270747931 0.19005280951759498 0.18053225852732663\n"
     ]
    }
   ],
   "source": [
    "# meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "# stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "# meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "# meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "# meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "# stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "# stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "# stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "# print(\"test 평균\",meanR, meanG, meanB)\n",
    "# print(\"test 표준편차\",stdR, stdG, stdB)\n",
    "\n",
    "# test 평균 0.41825619520929724 0.3931011906330291 0.386631764639131\n",
    "# test 표준편차 0.19505524270747931 0.19005280951759498 0.18053225852732663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1652400017289,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    # def __init__(self, img_paths, labels, mode='train'):\n",
    "    #     self.img_paths = img_paths\n",
    "    #     self.labels = labels\n",
    "    #     self.mode=mode\n",
    "    def __init__(self, img_paths, labels, classes, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "        self.classes=classes\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "            if self.classes[idx]==7:\n",
    "                # print(idx, '7')\n",
    "                train_transform = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                            std = [0.181572, 0.174035, 0.163234]),\n",
    "                        transforms.RandomAffine((-45, 45)),\n",
    "                    \n",
    "                        # transforms.RandomVerticalFlip(p=0.5),   # - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
    "                        # transforms.RandomHorizontalFlip(p=0.5), # - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
    "                        transforms.RandomRotation((0,80))       #  이미지를 랜덤으로 degrees 각도로 회전한다.\n",
    "                        \n",
    "                    ])\n",
    "                img = train_transform(img)\n",
    "            else :\n",
    "                train_transform = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                            std = [0.181572, 0.174035, 0.163234]),\n",
    "                        transforms.RandomAffine((-45, 45)),\n",
    "                    \n",
    "                        transforms.RandomVerticalFlip(p=0.5),   # - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
    "                        transforms.RandomHorizontalFlip(p=0.5), # - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
    "                        transforms.RandomRotation((0,80))       #  이미지를 랜덤으로 degrees 각도로 회전한다.\n",
    "                        \n",
    "                    ])\n",
    "                img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323]),\n",
    "              \n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88, drop_path_rate = 0.2)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88, drop_path_rate = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1652400017290,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "EnOG2n30-Dz5",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1652400017290,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "EnOG2n30-Dz5"
   },
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0sHMqIWSBHsJ",
   "metadata": {
    "id": "0sHMqIWSBHsJ"
   },
   "source": [
    "## StaratifieldKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lkNCkyG9RPzX",
    "outputId": "d81476fe-ff5d-45dd-dc8e-bf9bb87eaeec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 194s/13377s\n",
      "TRAIN    loss : 1.06271    f1 : 0.19991\n",
      "Val    loss : 0.53866    f1 : 0.33082\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 180s/12210s\n",
      "TRAIN    loss : 0.50609    f1 : 0.37492\n",
      "Val    loss : 0.39828    f1 : 0.44426\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 167s/11203s\n",
      "TRAIN    loss : 0.37039    f1 : 0.56183\n",
      "Val    loss : 0.28328    f1 : 0.58649\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 168s/11056s\n",
      "TRAIN    loss : 0.30820    f1 : 0.59011\n",
      "Val    loss : 0.21666    f1 : 0.61284\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 167s/10849s\n",
      "TRAIN    loss : 0.23587    f1 : 0.69419\n",
      "Val    loss : 0.22197    f1 : 0.73400\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 167s/10697s\n",
      "TRAIN    loss : 0.19172    f1 : 0.74630\n",
      "Val    loss : 0.11249    f1 : 0.79707\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/70    time : 167s/10525s\n",
      "TRAIN    loss : 0.14890    f1 : 0.78450\n",
      "Val    loss : 0.08893    f1 : 0.85555\n",
      "epoch : 8/70    time : 166s/10289s\n",
      "TRAIN    loss : 0.13520    f1 : 0.81985\n",
      "Val    loss : 0.10474    f1 : 0.83327\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/70    time : 176s/10708s\n",
      "TRAIN    loss : 0.11765    f1 : 0.85053\n",
      "Val    loss : 0.08126    f1 : 0.86128\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/70    time : 175s/10525s\n",
      "TRAIN    loss : 0.10243    f1 : 0.88477\n",
      "Val    loss : 0.05876    f1 : 0.89792\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/70    time : 176s/10364s\n",
      "TRAIN    loss : 0.09110    f1 : 0.87531\n",
      "Val    loss : 0.03367    f1 : 0.92837\n",
      "epoch : 12/70    time : 168s/9735s\n",
      "TRAIN    loss : 0.08543    f1 : 0.88553\n",
      "Val    loss : 0.04637    f1 : 0.92528\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/70    time : 168s/9578s\n",
      "TRAIN    loss : 0.08123    f1 : 0.90775\n",
      "Val    loss : 0.03449    f1 : 0.95231\n",
      "epoch : 14/70    time : 167s/9359s\n",
      "TRAIN    loss : 0.06858    f1 : 0.91495\n",
      "Val    loss : 0.04648    f1 : 0.94537\n",
      "epoch : 15/70    time : 167s/9194s\n",
      "TRAIN    loss : 0.05841    f1 : 0.92393\n",
      "Val    loss : 0.05095    f1 : 0.94684\n",
      "epoch : 16/70    time : 166s/8983s\n",
      "TRAIN    loss : 0.05169    f1 : 0.93264\n",
      "Val    loss : 0.03793    f1 : 0.91829\n",
      "-----------------SAVE:17 epoch----------------\n",
      "epoch : 17/70    time : 169s/8935s\n",
      "TRAIN    loss : 0.05958    f1 : 0.93157\n",
      "Val    loss : 0.02765    f1 : 0.97355\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/70    time : 168s/8750s\n",
      "TRAIN    loss : 0.04864    f1 : 0.94365\n",
      "Val    loss : 0.01973    f1 : 0.98012\n",
      "epoch : 19/70    time : 167s/8495s\n",
      "TRAIN    loss : 0.03887    f1 : 0.94481\n",
      "Val    loss : 0.01881    f1 : 0.96308\n",
      "epoch : 20/70    time : 167s/8334s\n",
      "TRAIN    loss : 0.03422    f1 : 0.95548\n",
      "Val    loss : 0.01359    f1 : 0.97089\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/70    time : 167s/8183s\n",
      "TRAIN    loss : 0.03376    f1 : 0.95880\n",
      "Val    loss : 0.02180    f1 : 0.98508\n",
      "epoch : 22/70    time : 167s/8037s\n",
      "TRAIN    loss : 0.04375    f1 : 0.94875\n",
      "Val    loss : 0.01384    f1 : 0.98217\n",
      "epoch : 23/70    time : 168s/7882s\n",
      "TRAIN    loss : 0.03908    f1 : 0.95497\n",
      "Val    loss : 0.01578    f1 : 0.97908\n",
      "epoch : 24/70    time : 168s/7724s\n",
      "TRAIN    loss : 0.03456    f1 : 0.96220\n",
      "Val    loss : 0.01429    f1 : 0.97532\n",
      "epoch : 25/70    time : 166s/7472s\n",
      "TRAIN    loss : 0.03544    f1 : 0.95603\n",
      "Val    loss : 0.02297    f1 : 0.95051\n",
      "-----------------SAVE:26 epoch----------------\n",
      "epoch : 26/70    time : 167s/7344s\n",
      "TRAIN    loss : 0.02508    f1 : 0.97373\n",
      "Val    loss : 0.00565    f1 : 0.99223\n",
      "epoch : 27/70    time : 167s/7198s\n",
      "TRAIN    loss : 0.02349    f1 : 0.97278\n",
      "Val    loss : 0.01872    f1 : 0.96949\n",
      "epoch : 28/70    time : 166s/6974s\n",
      "TRAIN    loss : 0.02596    f1 : 0.96807\n",
      "Val    loss : 0.02030    f1 : 0.98058\n",
      "epoch : 29/70    time : 166s/6799s\n",
      "TRAIN    loss : 0.01651    f1 : 0.98292\n",
      "Val    loss : 0.00408    f1 : 0.98247\n",
      "epoch : 30/70    time : 166s/6654s\n",
      "TRAIN    loss : 0.01708    f1 : 0.98354\n",
      "Val    loss : 0.03343    f1 : 0.97245\n",
      "epoch : 31/70    time : 168s/6534s\n",
      "TRAIN    loss : 0.02052    f1 : 0.98113\n",
      "Val    loss : 0.01512    f1 : 0.99156\n",
      "-----------------SAVE:32 epoch----------------\n",
      "epoch : 32/70    time : 168s/6369s\n",
      "TRAIN    loss : 0.02124    f1 : 0.97186\n",
      "Val    loss : 0.00614    f1 : 0.99305\n",
      "epoch : 33/70    time : 167s/6163s\n",
      "TRAIN    loss : 0.01819    f1 : 0.98002\n",
      "Val    loss : 0.01749    f1 : 0.98156\n",
      "-----------------SAVE:34 epoch----------------\n",
      "epoch : 34/70    time : 168s/6033s\n",
      "TRAIN    loss : 0.02314    f1 : 0.97870\n",
      "Val    loss : 0.00410    f1 : 1.00000\n",
      "epoch : 35/70    time : 167s/5842s\n",
      "TRAIN    loss : 0.01834    f1 : 0.97725\n",
      "Val    loss : 0.00207    f1 : 1.00000\n",
      "epoch : 36/70    time : 166s/5656s\n",
      "TRAIN    loss : 0.01431    f1 : 0.97413\n",
      "Val    loss : 0.00762    f1 : 0.99242\n",
      "epoch : 37/70    time : 166s/5466s\n",
      "TRAIN    loss : 0.01239    f1 : 0.99270\n",
      "Val    loss : 0.04301    f1 : 0.96216\n",
      "epoch : 38/70    time : 167s/5341s\n",
      "TRAIN    loss : 0.01685    f1 : 0.98662\n",
      "Val    loss : 0.00837    f1 : 0.99067\n",
      "epoch : 39/70    time : 167s/5192s\n",
      "TRAIN    loss : 0.02011    f1 : 0.98360\n",
      "Val    loss : 0.01395    f1 : 0.97693\n",
      "epoch : 40/70    time : 167s/5010s\n",
      "TRAIN    loss : 0.01869    f1 : 0.97973\n",
      "Val    loss : 0.01493    f1 : 0.97745\n",
      "epoch : 41/70    time : 166s/4806s\n",
      "TRAIN    loss : 0.01163    f1 : 0.98648\n",
      "Val    loss : 0.01042    f1 : 0.99432\n",
      "epoch : 42/70    time : 166s/4647s\n",
      "TRAIN    loss : 0.01483    f1 : 0.98012\n",
      "Val    loss : 0.00300    f1 : 1.00000\n",
      "epoch : 43/70    time : 166s/4477s\n",
      "TRAIN    loss : 0.00897    f1 : 0.98863\n",
      "Val    loss : 0.00501    f1 : 0.99585\n",
      "epoch : 44/70    time : 166s/4313s\n",
      "TRAIN    loss : 0.01096    f1 : 0.98867\n",
      "Val    loss : 0.00280    f1 : 0.99825\n",
      "epoch : 45/70    time : 166s/4138s\n",
      "TRAIN    loss : 0.01115    f1 : 0.98792\n",
      "Val    loss : 0.00966    f1 : 0.96856\n",
      "epoch : 46/70    time : 166s/3978s\n",
      "TRAIN    loss : 0.01346    f1 : 0.98583\n",
      "Val    loss : 0.00490    f1 : 0.98459\n",
      "epoch : 47/70    time : 166s/3809s\n",
      "TRAIN    loss : 0.01120    f1 : 0.97929\n",
      "Val    loss : 0.00409    f1 : 0.98851\n",
      "epoch : 48/70    time : 168s/3692s\n",
      "TRAIN    loss : 0.00884    f1 : 0.98888\n",
      "Val    loss : 0.00107    f1 : 1.00000\n",
      "epoch : 49/70    time : 173s/3623s\n",
      "TRAIN    loss : 0.00693    f1 : 0.99372\n",
      "Val    loss : 0.00355    f1 : 0.99459\n",
      "epoch : 50/70    time : 174s/3483s\n",
      "TRAIN    loss : 0.01433    f1 : 0.98764\n",
      "Val    loss : 0.01096    f1 : 0.99242\n",
      "epoch : 51/70    time : 172s/3261s\n",
      "TRAIN    loss : 0.00762    f1 : 0.99478\n",
      "Val    loss : 0.00892    f1 : 0.98831\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022,shuffle=True)\n",
    "batch_size = 32\n",
    "epochs = 70\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "#   # Train\n",
    "#   train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "#   train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "#   # Val\n",
    "#   val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "#   val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), np.array(train_classes), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), np.array([]), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "#   optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay = 2e-2)\n",
    "  optimizer = torch.optim.Adadelta(model.parameters())\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'0513_best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "id": "Jl2OKpQiO5S1"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m   model_test \u001b[38;5;241m=\u001b[39m \u001b[43mNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m   model_test\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload((path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0513_best_model_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i)))[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m   model_test\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_TF2\\lib\\site-packages\\torch\\nn\\modules\\module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    904\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_TF2\\lib\\site-packages\\torch\\nn\\modules\\module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_TF2\\lib\\site-packages\\torch\\nn\\modules\\module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_TF2\\lib\\site-packages\\torch\\nn\\modules\\module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_TF2\\lib\\site-packages\\torch\\nn\\modules\\module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_TF2\\lib\\site-packages\\torch\\cuda\\__init__.py:210\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 32\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), np.array(train_classes), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'0513_best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seat84vNOOtT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seat84vNOOtT",
    "outputId": "71c853b2-29c3-430e-e4d0-cb1a66e11196"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"data/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"submission/b45F_norm_epoch70_4_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p87_msjB7L51",
   "metadata": {
    "id": "p87_msjB7L51"
   },
   "source": [
    "## Efficientb4 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MW9Fx7QADii5",
   "metadata": {
    "id": "MW9Fx7QADii5"
   },
   "source": [
    "사전 학습 모델의 성능 파악을 할 때 Fold 학습은 실행 시간이 오래걸려서 fold를 나누지 않은 데이터에 대해서 학습을 진행하고 성능을 비교하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "syUpL8e_7L50",
   "metadata": {
    "executionInfo": {
     "elapsed": 2139,
     "status": "ok",
     "timestamp": 1652400037476,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "syUpL8e_7L50"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), np.array(train_classes), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), np.array([]), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cJc8Yj7zrh4g",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1652400037477,
     "user": {
      "displayName": "jiyeon seo",
      "userId": "13077474525846695766"
     },
     "user_tz": -540
    },
    "id": "cJc8Yj7zrh4g"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tpCGp41k7L51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpCGp41k7L51",
    "outputId": "bc053cc5-ced2-45f4-c1cf-f571405a01aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_ra2_320-7eb33cd5.pth\n"
     ]
    }
   ],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay = 1e-3)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), weight_decay = 1e-3)\n",
    "optimizer = torch.optim.Adadelta(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YssPW4xq7L53",
   "metadata": {
    "id": "YssPW4xq7L53"
   },
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1w_VB_PY7L53",
   "metadata": {
    "id": "1w_VB_PY7L53"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "pred_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "            pred_prob.extend(pred.detach().cpu().numpy())\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aZMML2u3DTHx",
   "metadata": {
    "id": "aZMML2u3DTHx"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I4io2mJC7L54",
   "metadata": {
    "id": "I4io2mJC7L54"
   },
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XCV3FEKe7L55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1652366803317,
     "user": {
      "displayName": "Jiyeon Seo",
      "userId": "13545171303062516687"
     },
     "user_tz": -540
    },
    "id": "XCV3FEKe7L55",
    "outputId": "1b189e4b-2176-4587-9006-bef1808afe25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3279c721-66eb-4500-9590-61c40a0ab11f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3279c721-66eb-4500-9590-61c40a0ab11f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3279c721-66eb-4500-9590-61c40a0ab11f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3279c721-66eb-4500-9590-61c40a0ab11f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"data/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jsl6tXbz7L56",
   "metadata": {
    "id": "jsl6tXbz7L56"
   },
   "outputs": [],
   "source": [
    "# efficient b4, 30 epoch, adadelta, allflip\n",
    "submission.to_csv(path + \"submission/0512_b4_norm_30epoch_allflip.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ed5c0",
   "metadata": {
    "id": "171ed5c0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "0512_Efficientnet_b4_exceptNut.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
