{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d57cc01",
   "metadata": {},
   "source": [
    "## 1. label 별 폴더만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6b815e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"./data/train_df.csv\")\n",
    "print(len(train_df[\"label\"].unique()))  # type = numpy.array\n",
    "label_list = train_df[\"label\"].unique().tolist()\n",
    "len(label_list)  # type = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c482bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    " \n",
    "for i in range(len(label_list)):  # 레이블 개수 만큼 \n",
    "    createFolder(f'./data/train_ex/{label_list[i]}')  # 레이블 폴더를 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19798db8",
   "metadata": {},
   "source": [
    "## 2. 이미지 파일을 레이블에 맞게 각 폴더로 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10366636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4365"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder = os.listdir('./data/train_ex/')\n",
    "len(train_folder)  # -폴더개수 88 , 사진개수 = 4277개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6eab64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for i in range(len(train_folder) - 88):  # 폴더 생성한것 88개 뺴주는 겁니다.\n",
    "    \n",
    "    if train_folder[i][-3:] == \"png\":   # 확장자가 png면 \n",
    "        label = train_df.loc[train_df[\"file_name\"] == f\"{train_folder[i]}\"][\"label\"][i]  # train_df에서 이미지 이름에 맞는 label을 불러와 저장\n",
    "        file_source = f'./data/train_ex/{train_folder[i]}'  # train 폴더에 있는 해당 이미지를\n",
    "        file_destination = f'./data/train_ex/{label}/'  # 해당 label 폴더로 이동 \n",
    "        shutil.move(file_source, file_destination)  # 이동 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729d3622",
   "metadata": {},
   "source": [
    "## 3. 이미지 전처리와 데이터 split 까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb05b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56db98bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: './train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# train data, test data 다르게 nomalization 적용하려면 data_dir 바꾸세요.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mget_mean_std\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mget_mean_std\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m이미지 정규화 시 성능 향상 , 평균과 표준편차로 정규화 실행\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mdata_dir = 이미지 들어있는 폴더 path\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      6\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      7\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m)),\n\u001b[0;32m      8\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor()\n\u001b[0;32m      9\u001b[0m ])\n\u001b[1;32m---> 11\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m데이터 정보\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataset)\n\u001b[0;32m     14\u001b[0m meanRGB \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mmean(x\u001b[38;5;241m.\u001b[39mnumpy(), axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m x,_ \u001b[38;5;129;01min\u001b[39;00m dataset]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_TF2\\lib\\site-packages\\torchvision\\datasets\\folder.py:310\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    304\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m ):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_TF2\\lib\\site-packages\\torchvision\\datasets\\folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    137\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    143\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 145\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_TF2\\lib\\site-packages\\torchvision\\datasets\\folder.py:219\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_TF2\\lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: './train'"
     ]
    }
   ],
   "source": [
    "def get_mean_std(data_dir):\n",
    "    '''\n",
    "    이미지 정규화 시 성능 향상 , 평균과 표준편차로 정규화 실행\n",
    "    data_dir = 이미지 들어있는 폴더 path\n",
    "    '''\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(os.path.join(f'./{data_dir}'), transform)\n",
    "    print(\"데이터 정보\", dataset)\n",
    "\n",
    "    meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x,_ in dataset]\n",
    "    stdRGB = [np.std(x.numpy(), axis=(1,2)) for x,_ in dataset]\n",
    "\n",
    "    meanR = np.mean([m[0] for m in meanRGB])\n",
    "    meanG = np.mean([m[1] for m in meanRGB])\n",
    "    meanB = np.mean([m[2] for m in meanRGB])\n",
    "\n",
    "    stdR = np.mean([s[0] for s in stdRGB])\n",
    "    stdG = np.mean([s[1] for s in stdRGB])\n",
    "    stdB = np.mean([s[2] for s in stdRGB])\n",
    "    print(\"평균\",meanR, meanG, meanB)\n",
    "    print(\"표준편차\",stdR, stdG, stdB)\n",
    "\n",
    "# train data, test data 다르게 nomalization 적용하려면 data_dir 바꾸세요.\n",
    "data_dir = \"train\"\n",
    "get_mean_std(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842de357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1024x1024 resize train / meanR=0.43303847, meanG=0.4034577, meanB=0.39415097  / stdR=0.18344551, stdG=0.17549995, stdB=0.1647388   \n",
    "# 128x128 resize train / meanR=0.43305725, meanG=0.40347522, meanB=0.3941705  / stdR=0.17281055, stdG=0.16584247, stdB=0.15571058 \n",
    "\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "\n",
    "data_dir = \"./\"\n",
    "\n",
    "def create_datasets(batch_size):\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # 좌우반전 \n",
    "    transforms.RandomVerticalFlip(),  # 상하반전 \n",
    "    transforms.Resize((1024, 1024)),  # 알맞게 변경하세요 \n",
    "    transforms.ToTensor(),  # 이 과정에서 [0, 255]의 범위를 갖는 값들을 [0.0, 1.0]으로 정규화, torch.FloatTensor로 변환\n",
    "    transforms.Normalize([0.43303847,0.4034577, 0.39415097], [0.18344551,0.17549995, 0.1647388])  #  정규화(normalization)\n",
    "])\n",
    "    test_transform = transforms.Compose([   # 나중에 test 데이터 불러올 때 참고하세요. \n",
    "    transforms.Resize((1024, 1024)),\n",
    "    transforms.ToTensor(), # 이 과정에서 [0, 255]의 범위를 갖는 값들을 [0.0, 1.0]으로 정규화 \n",
    "    transforms.Normalize([0.43303847,0.4034577, 0.39415097], [0.18344551,0.17549995, 0.1647388])  # 테스트 데이터로 계산을 진행해서 따로 지정해주어도 좋습니다\n",
    "])\n",
    "\n",
    "    # choose the training and test datasets\n",
    "    train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), train_transform)\n",
    "\n",
    "\n",
    "    # trainning set 중 validation 데이터로 사용할 비율\n",
    "    valid_size = 0.3\n",
    "\n",
    "    # validation으로 사용할 trainning indices를 얻는다.\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # trainning, validation batch를 얻기 위한 sampler정의\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # load training data in batches\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=train_sampler,\n",
    "                                               num_workers=4)\n",
    "\n",
    "    # load validation data in batches\n",
    "    valid_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=valid_sampler,\n",
    "                                               num_workers=4)\n",
    "\n",
    "    return train_data, train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544cca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_data, train_loader, valid_loader = create_datasets(batch_size=4)\n",
    "\n",
    "\n",
    "print('train 데이터셋 크기:', len(train_data))\n",
    "\n",
    "class_names = train_data.classes\n",
    "print('클래스:', class_names)\n",
    "\n",
    "def imshow(input, title):\n",
    "    # torch.Tensor를 numpy 객체로 변환\n",
    "    input = input.numpy().transpose((1, 2, 0))\n",
    "    # 이미지 정규화 해제하기\n",
    "    mean = np.array([0.43303847, 0.4034577, 0.39415097])\n",
    "    std = np.array([0.18344551, 0.17549995, 0.1647388])\n",
    "    input = std * input + mean\n",
    "    input = np.clip(input, 0, 1)\n",
    "\n",
    "    # 이미지 출력\n",
    "    plt.imshow(input)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 학습 데이터를 배치 단위로 불러오기\n",
    "iterator = iter(train_loader)\n",
    "\n",
    "# 현재 배치를 이용해 격자 형태의 이미지를 만들어 시각화\n",
    "inputs, classes = next(iterator)\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out, title=[class_names[x] for x in classes])\n",
    "print(inputs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF2] *",
   "language": "python",
   "name": "conda-env-machine_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
