{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob(path + 'data/train/*.png'))\n",
    "test_png = sorted(glob(path + 'data/test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atSgPJRn-OCW",
    "outputId": "87b6f90b-5c1c-4a0e-de54-994458543687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4277, 2154)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"data/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4277/4277 [02:04<00:00, 34.43it/s]\n",
      "100%|███████████████████████████████████████| 2154/2154 [01:02<00:00, 34.61it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "np.save(path + 'data/train_imgs_384', np.array(train_imgs))\n",
    "np.save(path + 'data/test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'data/train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'data/test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sscGLiJKPy6H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sscGLiJKPy6H",
    "outputId": "976516c0-507d-458f-f0c4-6695751605d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.4330380901867049 0.4034575319032911 0.39415050509784405\n",
      "train 표준편차 0.1815717110252788 0.17403455556798705 0.16323395055036488\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"train 평균\",meanR, meanG, meanB)\n",
    "print(\"train 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "JwVIQCrUSCFE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwVIQCrUSCFE",
    "outputId": "293981ef-7f6a-4602-d208-5fd8473d5261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.41825619520929724 0.3931011906330291 0.386631764639131\n",
      "test 표준편차 0.19505524270747931 0.19005280951759498 0.18053225852732663\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"test 평균\",meanR, meanG, meanB)\n",
    "print(\"test 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                     std = [0.181572, 0.174035, 0.163234]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "              \n",
    "                transforms.RandomVerticalFlip(p=0.5),   # - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
    "                transforms.RandomHorizontalFlip(p=0.5), # - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
    "                transforms.RandomRotation((0,80))       #  이미지를 랜덤으로 degrees 각도로 회전한다.\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323]),\n",
    "              \n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88, drop_path_rate = 0.2)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88, drop_path_rate = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "EnOG2n30-Dz5",
   "metadata": {
    "id": "EnOG2n30-Dz5"
   },
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 133s/9200s\n",
      "TRAIN    loss : 1.64812    f1 : 0.14730\n",
      "Val    loss : 0.74493    f1 : 0.19655\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 134s/9142s\n",
      "TRAIN    loss : 0.65348    f1 : 0.24237\n",
      "Val    loss : 0.53026    f1 : 0.29620\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 135s/9060s\n",
      "TRAIN    loss : 0.48342    f1 : 0.36397\n",
      "Val    loss : 0.42242    f1 : 0.39336\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 136s/8956s\n",
      "TRAIN    loss : 0.41730    f1 : 0.44508\n",
      "Val    loss : 0.41021    f1 : 0.41958\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 136s/8825s\n",
      "TRAIN    loss : 0.35290    f1 : 0.53031\n",
      "Val    loss : 0.32507    f1 : 0.55565\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 137s/8741s\n",
      "TRAIN    loss : 0.29509    f1 : 0.58247\n",
      "Val    loss : 0.30980    f1 : 0.59197\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3507/572357878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/machine_TF2_20/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/machine_TF2_20/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022,shuffle=True)\n",
    "batch_size = 32\n",
    "epochs = 70\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay = 2e-2)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2OKpQiO5S1",
    "outputId": "e48def07-ef6d-4325-f297-c705088b3eb8"
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 32\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "seat84vNOOtT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seat84vNOOtT",
    "outputId": "71c853b2-29c3-430e-e4d0-cb1a66e11196"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"data/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"data/submission/b3_norm_epoch70_4_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p87_msjB7L51",
   "metadata": {
    "id": "p87_msjB7L51"
   },
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MW9Fx7QADii5",
   "metadata": {
    "id": "MW9Fx7QADii5"
   },
   "source": [
    "사전 학습 모델의 성능 파악을 할 때 Fold 학습은 실행 시간이 오래걸려서 fold를 나누지 않은 데이터에 대해서 학습을 진행하고 성능을 비교하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "syUpL8e_7L50",
   "metadata": {
    "id": "syUpL8e_7L50"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cJc8Yj7zrh4g",
   "metadata": {
    "id": "cJc8Yj7zrh4g"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "tpCGp41k7L51",
   "metadata": {
    "id": "tpCGp41k7L51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/40    time : 147s/5729s\n",
      "TRAIN    loss : 2.76980    f1 : 0.12848\n",
      "epoch : 2/40    time : 149s/5660s\n",
      "TRAIN    loss : 0.99891    f1 : 0.15544\n",
      "epoch : 3/40    time : 150s/5547s\n",
      "TRAIN    loss : 0.78136    f1 : 0.17370\n",
      "epoch : 4/40    time : 150s/5417s\n",
      "TRAIN    loss : 0.63813    f1 : 0.21892\n",
      "epoch : 5/40    time : 151s/5270s\n",
      "TRAIN    loss : 0.54607    f1 : 0.28940\n",
      "epoch : 6/40    time : 151s/5125s\n",
      "TRAIN    loss : 0.49785    f1 : 0.32008\n",
      "epoch : 7/40    time : 151s/4987s\n",
      "TRAIN    loss : 0.45932    f1 : 0.37298\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3507/2982926037.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/machine_TF2_20/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/machine_TF2_20/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/machine_TF2_20/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/machine_TF2_20/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3507/927169967.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             ])\n\u001b[0;32m---> 22\u001b[0;31m           \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m           test_transform = transforms.Compose([\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/machine_TF2_20/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/machine_TF2_20/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/machine_TF2_20/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YssPW4xq7L53",
   "metadata": {
    "id": "YssPW4xq7L53"
   },
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1w_VB_PY7L53",
   "metadata": {
    "id": "1w_VB_PY7L53"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "pred_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "            pred_prob.extend(pred.detach().cpu().numpy())\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aZMML2u3DTHx",
   "metadata": {
    "id": "aZMML2u3DTHx"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I4io2mJC7L54",
   "metadata": {
    "id": "I4io2mJC7L54"
   },
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "XCV3FEKe7L55",
   "metadata": {
    "id": "XCV3FEKe7L55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"data/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "jsl6tXbz7L56",
   "metadata": {
    "id": "jsl6tXbz7L56"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"data/submission/0512_b4_norm_40epoch.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ed5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
